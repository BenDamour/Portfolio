{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import zipfile #to unszip our data\n",
    "\n",
    "#!kaggle competitions download -c titanic -p dataset\n",
    "\n",
    "\n",
    "myzip = zipfile.ZipFile(os.path.join('dataset',os.listdir('dataset')[0]))\n",
    "myzip.extractall(path=\"dataset\")\n",
    "myzip.close()\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "Train_path = 'dataset/train.csv'\n",
    "Test_path = 'dataset/test.csv'\n",
    "\n",
    "Data_train = pd.read_csv(Train_path)\n",
    "Data_test = pd.read_csv(Test_path)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='dataset/data_dict.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that some Cabin is Nan, let's check if there is others missing values in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "Data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact we have missing value for: \n",
    "- Age (177 null)\n",
    "\n",
    "Here we have two options : We could discard the instance where age is null OR We could fill the missing values with median. Since the missing values represent almost 20% of the passengers, I think it's bette to fill the missing values. Indeed, if we discard them, we will have a shorter training set (it's not good when we would like to fit our data with models). \n",
    "\n",
    "- Cabin (687 null)\n",
    "\n",
    "Since for the Cabin feature we have to much missing data, we can omit this feature from our data. Moreover, the cabin could be related to ticket price (fare, which is complete) or related to the Pclass (1st class could have the best cabin, etc.)\n",
    "\n",
    "- Embarked (2 null)\n",
    "\n",
    "For this last feature, we could discard the 2 missings instances, or put a random value, for example we could put 'C'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data_train.Age.fillna(Data_train.Age.median(),inplace=True)\n",
    "Data_train = Data_train.drop(['Cabin'],axis=1)\n",
    "Data_train.Embarked.fillna('C',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Embarked     891 non-null    object \n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "Data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue by completed the missing values for age and for Embarked :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note \n",
    "We can also discard the name (useless) and the ticket (We make the asumption that there is correlation between ticket and the Fare or the Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['Name','Ticket']\n",
    "Data_train = Data_train.drop(features_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          891 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Fare         891 non-null    float64\n",
      " 8   Embarked     891 non-null    object \n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "Data_train.info()\n",
    "# Since we don't have missing values, we can complete to clean our data. We have still two object type (Sex and Embarked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    644\n",
      "C    170\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64 \n",
      "\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Data_train.Embarked.value_counts(),'\\n')\n",
    "print(Data_train.Sex.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 2 categories for Sex : we could replace male by 0 and female by 1.\n",
    "For the Embarked feature, we could make an OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train.Sex.replace(['male','female'],[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "Embarked_cat = Data_train[['Embarked']]\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "Embarked_cat_1hot = encoder.fit_transform(Embarked_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the transformation \n",
    "\n",
    "We have now a good insight about how we have to make the transformation on our data. Since we want to make something good, we could build a pipeline to transform our data (Fit_Transform on our Data_train AND Transform on Data_Test). For this purpose, we will use ColumnTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create our own transformer to change the following features as discused above:\n",
    "- Sex\n",
    "- Age \n",
    "- Name\n",
    "- Ticket\n",
    "- Cabin\n",
    "- Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train = pd.read_csv(Train_path,index_col=0)\n",
    "y_survived = Data_train.Survived.copy()\n",
    "\n",
    "Data_train.drop(['Survived'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                 3                             Heikkinen, Miss. Laina   \n",
       "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                 3                           Allen, Mr. William Henry   \n",
       "\n",
       "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "1              male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "3            female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "4            female  35.0      1      0            113803  53.1000  C123   \n",
       "5              male  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "            Embarked  \n",
       "PassengerId           \n",
       "1                  S  \n",
       "2                  C  \n",
       "3                  S  \n",
       "4                  S  \n",
       "5                  S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   \\nData_Transformer = ColumnTransformer([\\n    (\"non_cat_features\",Change_Non_Cat_Features(),non_cat_features),\\n    #(\"Fill_Median_Value\", SimpleImputer(strategy=\\'median\\'),scaled_features),    \\n    (\"scaled\",MinMaxScaler(), []),\\n    (\"cat_feature\",OneHotEncoder(), cat_feature)])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class Change_Non_Cat_Features(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        X.drop(['Cabin','Name','Ticket'],axis=1,inplace=True)\n",
    "        X.Sex.replace(['male','female'],[1,0],inplace=True)\n",
    "        return np.c_[X]\n",
    "    \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "cat_feature = ['Embarked']\n",
    "\n",
    "non_cat_features = list(Data_train)\n",
    "non_cat_features.remove('Embarked')\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([(\"non_cat_features\",Change_Non_Cat_Features()),\n",
    "                         (\"fill_miss_value\",SimpleImputer()),\n",
    "                         (\"scaled\",MinMaxScaler())])    \n",
    "  \n",
    "\n",
    "Data_Transformer = ColumnTransformer([\n",
    "    (\"non_cat_features\",num_pipeline, non_cat_features),\n",
    "    (\"cat_feature\",OneHotEncoder(), cat_feature)])\n",
    "    \n",
    "\"\"\"   \n",
    "Data_Transformer = ColumnTransformer([\n",
    "    (\"non_cat_features\",Change_Non_Cat_Features(),non_cat_features),\n",
    "    #(\"Fill_Median_Value\", SimpleImputer(strategy='median'),scaled_features),    \n",
    "    (\"scaled\",MinMaxScaler(), []),\n",
    "    (\"cat_feature\",OneHotEncoder(), cat_feature)])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(Train_path)\n",
    "\n",
    "Data.Embarked.fillna('C',inplace=True)\n",
    "Data = Data.drop(['Survived'],axis=1)\n",
    "\n",
    "Data_prepared = Data_Transformer.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to get the different columns\n",
    "\n",
    "# Get the columns for the one hot encoder\n",
    "hotencoder = Data_Transformer.named_transformers_['cat_feature']\n",
    "Embarked_list = list(hotencoder.categories_[0])\n",
    "\n",
    "Features_list = ['Pclass','Sex','Age','SibSp','Parch','Fare'] + Embarked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367921</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  SibSp     Parch      Fare    C    Q    S\n",
       "0       1.0  1.0  0.271174  0.125  0.000000  0.014151  0.0  0.0  1.0\n",
       "1       0.0  0.0  0.472229  0.125  0.000000  0.139136  1.0  0.0  0.0\n",
       "2       1.0  0.0  0.321438  0.000  0.000000  0.015469  0.0  0.0  1.0\n",
       "3       0.0  0.0  0.434531  0.125  0.000000  0.103644  0.0  0.0  1.0\n",
       "4       1.0  1.0  0.434531  0.000  0.000000  0.015713  0.0  0.0  1.0\n",
       "..      ...  ...       ...    ...       ...       ...  ...  ...  ...\n",
       "886     0.5  1.0  0.334004  0.000  0.000000  0.025374  0.0  0.0  1.0\n",
       "887     0.0  0.0  0.233476  0.000  0.000000  0.058556  0.0  0.0  1.0\n",
       "888     1.0  0.0  0.367921  0.125  0.333333  0.045771  0.0  0.0  1.0\n",
       "889     0.0  1.0  0.321438  0.000  0.000000  0.058556  1.0  0.0  0.0\n",
       "890     1.0  1.0  0.396833  0.000  0.000000  0.015127  0.0  1.0  0.0\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can rebuild a pandas DataFrame\n",
    "pd.DataFrame(Data_prepared,columns=Features_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's try to build a linear regression (basics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(Data_prepared,y_survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.2917948455907191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "surv_predict_lin = lin_reg.predict(Data_prepared)\n",
    "\n",
    "MAE = mean_absolute_error(y_survived,surv_predict_lin)\n",
    "print(\"MAE:\", MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_lin = cross_val_score(lin_reg,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='neg_mean_absolute_error',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MAE LINEAR CROSS : 0.2968126419667576\n",
      "std LINEAR CROSS : 0.010789090722755988\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MAE LINEAR CROSS :\",(-scores_lin).mean())\n",
    "print(\"std LINEAR CROSS :\",(-scores_lin).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.017957351290684626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(criterion='mae')\n",
    "tree_reg.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_tree = tree_reg.predict(Data_prepared)\n",
    "\n",
    "\n",
    "Tree_MAE = mean_absolute_error(y_survived,surv_predict_tree)\n",
    "print(\"MAE:\", Tree_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tree = cross_val_score(tree_reg,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='neg_mean_absolute_error',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MAE TREE CROSS : 0.24017010859330865\n",
      "std TREE CROSS : 0.022189829509800148\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MAE TREE CROSS :\",(-scores_tree).mean())\n",
    "print(\"std TREE CROSS :\",(-scores_tree).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.017957351290684626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(criterion='mae')\n",
    "forest_reg.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_forest = forest_reg.predict(Data_prepared)\n",
    "\n",
    "Forest_MAE = mean_absolute_error(y_survived,surv_predict_forest)\n",
    "print(\"MAE:\", Tree_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_forest = cross_val_score(forest_reg,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='neg_mean_absolute_error',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MAE TREE CROSS : 0.2490265833908732\n",
      "std TREE CROSS : 0.019314783940571168\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MAE TREE CROSS :\",(-scores_forest).mean())\n",
    "print(\"std TREE CROSS :\",(-scores_forest).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR, NuSVR, LinearSVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.23610435288805906\n"
     ]
    }
   ],
   "source": [
    "SVR_reg = SVR()\n",
    "SVR_reg.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_SVR = SVR_reg.predict(Data_prepared)\n",
    "\n",
    "SVR_MAE = mean_absolute_error(y_survived,surv_predict_SVR)\n",
    "print(\"MAE:\", SVR_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_SVR = cross_val_score(SVR_reg,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='neg_mean_absolute_error',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MAE TREE CROSS : 0.2431311436906578\n",
      "std TREE CROSS : 0.015546675699856223\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MAE TREE CROSS :\",(-scores_SVR).mean())\n",
    "print(\"std TREE CROSS :\",(-scores_SVR).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.18833307812898967\n"
     ]
    }
   ],
   "source": [
    "NUSVR_reg = NuSVR()\n",
    "NUSVR_reg.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_NUSVR = NUSVR_reg.predict(Data_prepared)\n",
    "\n",
    "NUSVR_MAE = mean_absolute_error(y_survived,surv_predict_NUSVR)\n",
    "print(\"MAE:\", NUSVR_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_NUSVR = cross_val_score(NUSVR_reg,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='neg_mean_absolute_error',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MAE TREE CROSS : 0.19809193708075368\n",
      "std TREE CROSS : 0.02123178156751093\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MAE TREE CROSS :\",(-scores_NUSVR).mean())\n",
    "print(\"std TREE CROSS :\",(-scores_NUSVR).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.21324524464959654\n"
     ]
    }
   ],
   "source": [
    "LINSVR_reg = LinearSVR()\n",
    "LINSVR_reg.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_LINSVR = LINSVR_reg.predict(Data_prepared)\n",
    "\n",
    "LINSVR_MAE = mean_absolute_error(y_survived,surv_predict_LINSVR)\n",
    "print(\"MAE:\", LINSVR_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_LINSVR = cross_val_score(LINSVR_reg,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='neg_mean_absolute_error',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MAE TREE CROSS : 0.21328707290297003\n",
      "std TREE CROSS : 0.027735798687332364\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MAE TREE CROSS :\",(-scores_LINSVR).mean())\n",
    "print(\"std TREE CROSS :\",(-scores_LINSVR).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.20291806958473627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "KNR_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "KNR_reg.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_KNR = KNR_reg.predict(Data_prepared)\n",
    "\n",
    "KNR_MAE = mean_absolute_error(y_survived,surv_predict_KNR)\n",
    "print(\"MAE:\", KNR_MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_KNR = cross_val_score(KNR_reg,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='neg_mean_absolute_error',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MAE TREE CROSS : 0.2525102002385287\n",
      "std TREE CROSS : 0.010160241888024304\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MAE TREE CROSS :\",(-scores_KNR).mean())\n",
    "print(\"std TREE CROSS :\",(-scores_KNR).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that SVR (linSVR, NuSVR, SVR) doesn't overfit too much (MAE for the predict an all the training set is near the MAE from crossvalidation). \n",
    "\n",
    "Even if we don't overfitt the data, we can try to search the better parameter (Fine Tuning). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune the model with SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_SVR = [{'kernel':['linear'], 'C':[1,2,3,4],'verbose':[1]},\n",
    "                  {'kernel':['poly'], 'degree':[1,2,3],'verbose':[1]},\n",
    "                  {'kernel':['rbf'], 'gamma':[1,2,3],'verbose':[1]},\n",
    "                 ]\n",
    "SVR_reg = SVR()\n",
    "\n",
    "grid_search_SVR = GridSearchCV(SVR_reg,param_grid=param_grid_SVR,\n",
    "                               cv=5,scoring='neg_mean_absolute_error',\n",
    "                               verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=1, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=1, kernel=linear, verbose=1, score=-0.242, total=   0.0s\n",
      "[CV] C=1, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=1, kernel=linear, verbose=1, score=-0.253, total=   0.0s\n",
      "[CV] C=1, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=1, kernel=linear, verbose=1, score=-0.270, total=   0.0s\n",
      "[CV] C=1, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=1, kernel=linear, verbose=1, score=-0.311, total=   0.0s\n",
      "[CV] C=1, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=1, kernel=linear, verbose=1, score=-0.257, total=   0.0s\n",
      "[CV] C=2, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=2, kernel=linear, verbose=1, score=-0.242, total=   0.0s\n",
      "[CV] C=2, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=2, kernel=linear, verbose=1, score=-0.253, total=   0.0s\n",
      "[CV] C=2, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=2, kernel=linear, verbose=1, score=-0.270, total=   0.0s\n",
      "[CV] C=2, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=2, kernel=linear, verbose=1, score=-0.311, total=   0.0s\n",
      "[CV] C=2, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=2, kernel=linear, verbose=1, score=-0.257, total=   0.0s\n",
      "[CV] C=3, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=3, kernel=linear, verbose=1, score=-0.242, total=   0.0s\n",
      "[CV] C=3, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=3, kernel=linear, verbose=1, score=-0.252, total=   0.0s\n",
      "[CV] C=3, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=3, kernel=linear, verbose=1, score=-0.270, total=   0.0s\n",
      "[CV] C=3, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=3, kernel=linear, verbose=1, score=-0.311, total=   0.0s\n",
      "[CV] C=3, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=3, kernel=linear, verbose=1, score=-0.257, total=   0.0s\n",
      "[CV] C=4, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=4, kernel=linear, verbose=1, score=-0.242, total=   0.0s\n",
      "[CV] C=4, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=4, kernel=linear, verbose=1, score=-0.252, total=   0.0s\n",
      "[CV] C=4, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=4, kernel=linear, verbose=1, score=-0.270, total=   0.0s\n",
      "[CV] C=4, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=4, kernel=linear, verbose=1, score=-0.311, total=   0.0s\n",
      "[CV] C=4, kernel=linear, verbose=1 ...................................\n",
      "[LibSVM][CV] ...... C=4, kernel=linear, verbose=1, score=-0.257, total=   0.0s\n",
      "[CV] degree=1, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=1, kernel=poly, verbose=1, score=-0.243, total=   0.0s\n",
      "[CV] degree=1, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=1, kernel=poly, verbose=1, score=-0.253, total=   0.0s\n",
      "[CV] degree=1, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=1, kernel=poly, verbose=1, score=-0.271, total=   0.0s\n",
      "[CV] degree=1, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=1, kernel=poly, verbose=1, score=-0.311, total=   0.0s\n",
      "[CV] degree=1, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=1, kernel=poly, verbose=1, score=-0.257, total=   0.0s\n",
      "[CV] degree=2, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=2, kernel=poly, verbose=1, score=-0.236, total=   0.0s\n",
      "[CV] degree=2, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=2, kernel=poly, verbose=1, score=-0.246, total=   0.0s\n",
      "[CV] degree=2, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=2, kernel=poly, verbose=1, score=-0.253, total=   0.0s\n",
      "[CV] degree=2, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=2, kernel=poly, verbose=1, score=-0.279, total=   0.0s\n",
      "[CV] degree=2, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=2, kernel=poly, verbose=1, score=-0.223, total=   0.0s\n",
      "[CV] degree=3, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=3, kernel=poly, verbose=1, score=-0.242, total=   0.0s\n",
      "[CV] degree=3, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=3, kernel=poly, verbose=1, score=-0.249, total=   0.0s\n",
      "[CV] degree=3, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=3, kernel=poly, verbose=1, score=-0.240, total=   0.0s\n",
      "[CV] degree=3, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=3, kernel=poly, verbose=1, score=-0.268, total=   0.0s\n",
      "[CV] degree=3, kernel=poly, verbose=1 ................................\n",
      "[LibSVM][CV] ... degree=3, kernel=poly, verbose=1, score=-0.216, total=   0.0s\n",
      "[CV] gamma=1, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=1, kernel=rbf, verbose=1, score=-0.237, total=   0.0s\n",
      "[CV] gamma=1, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=1, kernel=rbf, verbose=1, score=-0.239, total=   0.0s\n",
      "[CV] gamma=1, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=1, kernel=rbf, verbose=1, score=-0.235, total=   0.0s\n",
      "[CV] gamma=1, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=1, kernel=rbf, verbose=1, score=-0.267, total=   0.0s\n",
      "[CV] gamma=1, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=1, kernel=rbf, verbose=1, score=-0.215, total=   0.0s\n",
      "[CV] gamma=2, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=2, kernel=rbf, verbose=1, score=-0.240, total=   0.0s\n",
      "[CV] gamma=2, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=2, kernel=rbf, verbose=1, score=-0.237, total=   0.0s\n",
      "[CV] gamma=2, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=2, kernel=rbf, verbose=1, score=-0.233, total=   0.0s\n",
      "[CV] gamma=2, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=2, kernel=rbf, verbose=1, score=-0.271, total=   0.0s\n",
      "[CV] gamma=2, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=2, kernel=rbf, verbose=1, score=-0.207, total=   0.0s\n",
      "[CV] gamma=3, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=3, kernel=rbf, verbose=1, score=-0.252, total=   0.0s\n",
      "[CV] gamma=3, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=3, kernel=rbf, verbose=1, score=-0.236, total=   0.0s\n",
      "[CV] gamma=3, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=3, kernel=rbf, verbose=1, score=-0.239, total=   0.0s\n",
      "[CV] gamma=3, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=3, kernel=rbf, verbose=1, score=-0.273, total=   0.0s\n",
      "[CV] gamma=3, kernel=rbf, verbose=1 ..................................\n",
      "[LibSVM][CV] ..... gamma=3, kernel=rbf, verbose=1, score=-0.204, total=   0.0s\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 2, 3, 4], 'kernel': ['linear'],\n",
       "                          'verbose': [1]},\n",
       "                         {'degree': [1, 2, 3], 'kernel': ['poly'],\n",
       "                          'verbose': [1]},\n",
       "                         {'gamma': [1, 2, 3], 'kernel': ['rbf'],\n",
       "                          'verbose': [1]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_SVR.fit(Data_prepared,y_survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 2, 'kernel': 'rbf', 'verbose': 1}\n",
      "MEAN_MAE_SVR,0.267 {'C': 1, 'kernel': 'linear', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.266 {'C': 2, 'kernel': 'linear', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.267 {'C': 3, 'kernel': 'linear', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.267 {'C': 4, 'kernel': 'linear', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.267 {'degree': 1, 'kernel': 'poly', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.248 {'degree': 2, 'kernel': 'poly', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.243 {'degree': 3, 'kernel': 'poly', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.239 {'gamma': 1, 'kernel': 'rbf', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.238 {'gamma': 2, 'kernel': 'rbf', 'verbose': 1} \n",
      "MEAN_MAE_SVR,0.241 {'gamma': 3, 'kernel': 'rbf', 'verbose': 1} \n"
     ]
    }
   ],
   "source": [
    "print(grid_search_SVR.best_params_) #0.238 MAE MEAN\n",
    "for mean,params in zip(grid_search_SVR.cv_results_[\"mean_test_score\"],grid_search_SVR.cv_results_[\"params\"]):\n",
    "    print(\"MEAN_MAE_SVR,{:.3} {} \".format(-mean,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.1, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.499, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True ..............\n",
      "[LibSVM][CV]  C=0.5, gamma=0.8, kernel=rbf, nu=0.2, verbose=True, score=-0.500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True, score=-0.519, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True, score=-0.483, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True, score=-0.479, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True, score=-0.474, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.1, verbose=True, score=-0.455, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True, score=-0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True, score=-0.579, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True, score=-0.531, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True, score=-0.684, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True ..........\n",
      "[LibSVM][CV]  C=0.1, gamma=0.8, kernel=sigmoid, nu=0.2, verbose=True, score=-0.560, total=   0.0s\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                             gamma='scale', kernel='rbf', max_iter=-1, nu=0.5,\n",
       "                             shrinking=True, tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.1, 0.5], 'gamma': [0.8], 'kernel': ['rbf'],\n",
       "                          'nu': [0.1, 0.2], 'verbose': [True]},\n",
       "                         {'C': [0.1], 'gamma': [0.8], 'kernel': ['sigmoid'],\n",
       "                          'nu': [0.1, 0.2], 'verbose': [True]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_NUSVR = [{'nu':[0.1,0.2], 'C':[0.1,0.5],\n",
    "                     'kernel':['rbf'], 'gamma':[0.8],'verbose':[True]},\n",
    "                    {'nu':[0.1,0.2], 'C':[0.1],\n",
    "                     'kernel':['sigmoid'], 'gamma':[0.8],'verbose':[True]},\n",
    "                  ]\n",
    "NUSVR_reg = NuSVR()\n",
    "\n",
    "grid_search_NUSVR = GridSearchCV(NUSVR_reg,param_grid=param_grid_NUSVR,\n",
    "                               cv=5,scoring='neg_mean_absolute_error',\n",
    "                               verbose=3)\n",
    "\n",
    "grid_search_NUSVR.fit(Data_prepared,y_survived)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 0.8, 'kernel': 'sigmoid', 'nu': 0.1, 'verbose': True}\n",
      "MEAN_MAE_NUSVR,0.5 {'C': 0.1, 'gamma': 0.8, 'kernel': 'rbf', 'nu': 0.1, 'verbose': True} \n",
      "MEAN_MAE_NUSVR,0.5 {'C': 0.1, 'gamma': 0.8, 'kernel': 'rbf', 'nu': 0.2, 'verbose': True} \n",
      "MEAN_MAE_NUSVR,0.5 {'C': 0.5, 'gamma': 0.8, 'kernel': 'rbf', 'nu': 0.1, 'verbose': True} \n",
      "MEAN_MAE_NUSVR,0.5 {'C': 0.5, 'gamma': 0.8, 'kernel': 'rbf', 'nu': 0.2, 'verbose': True} \n",
      "MEAN_MAE_NUSVR,0.482 {'C': 0.1, 'gamma': 0.8, 'kernel': 'sigmoid', 'nu': 0.1, 'verbose': True} \n",
      "MEAN_MAE_NUSVR,0.593 {'C': 0.1, 'gamma': 0.8, 'kernel': 'sigmoid', 'nu': 0.2, 'verbose': True} \n"
     ]
    }
   ],
   "source": [
    "print(grid_search_NUSVR.best_params_) # 0.197 MAE MEAN\n",
    "for mean,params in zip(grid_search_NUSVR.cv_results_[\"mean_test_score\"],grid_search_NUSVR.cv_results_[\"params\"]):\n",
    "    print(\"MEAN_MAE_NUSVR,{:.3} {} \".format(-mean,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the prediction for our model\n",
    "({'C': 0.5, 'gamma': 0.8, 'kernel': 'rbf', 'nu': 0.9, 'verbose': True} NUSVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test = pd.read_csv(Test_path)\n",
    "\n",
    "Data_test.Embarked.fillna('C',inplace=True)\n",
    "#Data = Data.drop(['Survived'],axis=1)\n",
    "\n",
    "Data_test_prepared = Data_Transformer.transform(Data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Data_test_prepared,columns=Features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search_NUSVR.best_estimator_\n",
    "final_model.fit(Data_prepared,y_survived)\n",
    "\n",
    "\n",
    "mean_absolute_error(y_survived,final_model.predict(Data_prepared))\n",
    "\n",
    "y_test_pred = final_model.predict(Data_test_prepared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output = pd.DataFrame({'PassengerId': Data_test.PassengerId,\n",
    "                       'Survived': y_test_pred})\n",
    "\n",
    "output.to_csv('dataset/submission.csv', index=False)\n",
    "#!kaggle competitions submit -c titanic -f dataset/submission.csv -m \"With rounded values (2nd)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try this with Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SVC_clf = SVC()\n",
    "SVC_clf.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_SVC = SVC_clf.predict(Data_prepared)\n",
    "\n",
    "SVC_ACCURACY = accuracy_score(y_survived,surv_predict_SVC)\n",
    "print(\"ACCURACY:\", SVC_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_SVC = cross_val_score(SVC_clf,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='accuracy',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_surv_pred = cross_val_predict(SVC_clf,Data_prepared,y_survived,\n",
    "                         verbose=0,cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_survived,y_surv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision and recall\n",
    "print(\"Precision:\", precision_score(y_survived,y_surv_pred))\n",
    "print(\"Recall:\", recall_score(y_survived,y_surv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is about 88% (Correctly classified) \n",
    "Detects only 58% of survided.\n",
    "\n",
    "We can plot the Precision/Recall curve, but we have to specify the method:decision_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_surv_scores = cross_val_predict (SVC_clf,Data_prepared,y_survived,\n",
    "                         verbose=0,cv=5,n_jobs=1,method='decision_function')\n",
    "\n",
    "precisions,recalls,thresholds = precision_recall_curve(y_survived,y_surv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_VS_threshold(precisions, recalls, thresholds):\n",
    "    #%matplotlib notebook \n",
    "    plt.plot(thresholds, precisions[:-1],'b--',label='Precision')\n",
    "    plt.plot(thresholds, recalls[:-1],'g-',label='Recall')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title(\"Precision and Recall VS Threshold\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_precision_recall_VS_threshold(precisions,recalls,thresholds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(precisions,recalls)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot([0.78, 0.78], [0.0, 0.78], \"b:\")\n",
    "plt.plot([0.4, 0.78], [0.78, 0.78], \"b:\")\n",
    "plt.plot([0.78], [0.78], \"ro\")\n",
    "plt.show()\n",
    "\n",
    "# For a threshold = -0,929522 we have a precision about 0.77 let's check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_70_precision = thresholds[np.argmax(precisions >=0.799)]\n",
    "threshold_70_precision #-0.765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_surv_pred_70 = (y_surv_scores >= threshold_70_precision)\n",
    "\n",
    "#Precision and recall\n",
    "print(\"Precision:\", precision_score(y_survived,y_surv_pred_70))\n",
    "print(\"Recall:\", recall_score(y_survived,y_surv_pred_70))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using predict method, we use the decision function. We will have the score for each instance, and we can compute the final result by selecting the correct threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test_pred_Classifier = (SVC_clf.decision_function(Data_test_prepared) >= threshold_70_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output = pd.DataFrame({'PassengerId': Data_test.PassengerId,\n",
    "                       'Survived': y_test_pred_Classifier})\n",
    "\n",
    "output.to_csv('dataset/submission.csv', index=False)\n",
    "#!kaggle competitions submit -c titanic -f dataset/submission.csv -m \"With rounded values (2nd)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_SVC = [\n",
    "                 {'kernel':['linear'],\n",
    "                   'C':uniform.rvs(loc=0,scale=1,size=500,random_state=0),\n",
    "                   'tol':uniform.rvs(loc=0,scale=1e-4,size=500,random_state=1)\n",
    "                     },\n",
    "                  {'kernel':['poly'],\n",
    "                   'degree':[1,2,3],\n",
    "                   'gamma':uniform.rvs(loc=0,scale=1,size=500,random_state=2),\n",
    "                   'coef0':uniform.rvs(loc=0,scale=1,size=500,random_state=5),\n",
    "                   #'C':uniform.rvs(loc=0,scale=1,size=500,random_state=3),\n",
    "                   'tol':uniform.rvs(loc=0,scale=1e-4,size=500,random_state=4)\n",
    "                     },\n",
    "                      ]\n",
    "\n",
    "grid_search_SVC = RandomizedSearchCV(SVC_clf,\n",
    "                               param_distributions=param_grid_SVC,\n",
    "                               cv=5,n_iter=10,scoring='accuracy',\n",
    "                               verbose=3)\n",
    "\n",
    "grid_search_SVC.fit(Data_prepared,y_survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean,params in zip(grid_search_SVC.cv_results_['mean_test_score'],grid_search_SVC.cv_results_['params']):\n",
    "    print(mean,\"\\n\", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_SVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search_SVC.best_estimator_\n",
    "\n",
    "final_model.fit(Data_prepared,y_survived)\n",
    "\n",
    "y_surv_pred = cross_val_predict(final_model,Data_prepared,y_survived,\n",
    "                         verbose=0,cv=5,n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion_Matrix\\n',confusion_matrix(y_survived,y_surv_pred))\n",
    "      \n",
    "#Precision and recall\n",
    "print(\"Precision:\", precision_score(y_survived,y_surv_pred))\n",
    "print(\"Recall:\", recall_score(y_survived,y_surv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions,recalls,thresholds = precision_recall_curve(y_survived,final_model.decision_function(Data_prepared))\n",
    "\n",
    "plot_precision_recall_VS_threshold(precisions,recalls,thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(precisions,recalls)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "# For a threshold = -0,929522 we have a precision about 0.77 let's check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_best_classifier = final_model.predict(Data_test_prepared)\n",
    "y_test_pred_best_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': Data_test.PassengerId, 'Survived': y_test_pred_best_classifier})\n",
    "\n",
    "output.to_csv('dataset/submission.csv', index=False)\n",
    "\n",
    "#!kaggle competitions submit -c titanic -f dataset/submission.csv -m \"With best SVC classifier (4th)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNC_clf = KNeighborsClassifier()\n",
    "KNC_clf.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_KNC= KNC_clf.predict(Data_prepared)\n",
    "\n",
    "KNC_ACCURACY = accuracy_score(y_survived,surv_predict_KNC)\n",
    "print(\"ACCURACY:\", KNC_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_KNC = cross_val_score(KNC_clf,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='accuracy',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_KNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_surv_pred_KNC = cross_val_predict(KNC_clf,Data_prepared,y_survived,\n",
    "                         verbose=0,cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_survived,y_surv_pred_KNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision and recall\n",
    "print(\"Precision:\", precision_score(y_survived,y_surv_pred_KNC))\n",
    "print(\"Recall:\", recall_score(y_survived,y_surv_pred_KNC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_KNC = KNC_clf.predict(Data_test_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output = pd.DataFrame({'PassengerId': Data_test.PassengerId,\n",
    "                       'Survived': y_test_pred_KNC})\n",
    "\n",
    "output.to_csv('dataset/submission.csv', index=False)\n",
    "#!kaggle competitions submit -c titanic -f dataset/submission.csv -m \"With rounded values (2nd)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Tree_clf = DecisionTreeClassifier()\n",
    "Tree_clf.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_tree_clf = Tree_clf.predict(Data_prepared)\n",
    "TREE_ACCURACY = accuracy_score(y_survived,surv_predict_tree_clf)\n",
    "print(\"ACCURACY:\", TREE_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_TREEC = cross_val_score(Tree_clf,Data_prepared,y_survived,\n",
    "                         verbose=0,scoring='accuracy',\n",
    "                         cv=5,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_TREEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Forest_clf = RandomForestClassifier()\n",
    "Forest_clf.fit(Data_prepared,y_survived)\n",
    "\n",
    "surv_predict_forest_clf = Forest_clf.predict(Data_prepared)\n",
    "FOREST_ACCURACY = accuracy_score(y_survived,surv_predict_forest_clf)\n",
    "print(\"ACCURACY:\", TREE_ACCURACY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer for categorical value ! \n",
    "\n",
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('numerical',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('fill_miss_value',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='median',\n",
       "                                                                verbose=0))],\n",
       "                                          verbose=False),\n",
       "                                 ['Age', 'SibSp', 'Parch', 'Fare']),\n",
       "                                ('categorical',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('fill_miss_value',\n",
       "                                                  MostFrequentImputer()),\n",
       "                                                 ('encoder',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=False))],\n",
       "                                          verbose=False),\n",
       "                                 ['Pclass', 'Sex', 'Embarked'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numerical attributes\n",
    "\n",
    "Numerical_attribs = ['Age','SibSp', 'Parch','Fare']\n",
    "\n",
    "new_num_pipiline = Pipeline([\n",
    "    (\"fill_miss_value\",SimpleImputer(strategy='median')),\n",
    "    #(\"scaled\",MinMaxScaler())                         \n",
    "                             ])\n",
    "Categorical_attribs = ['Pclass','Sex','Embarked']\n",
    "\n",
    "new_cat_pipeline = Pipeline([\n",
    "    (\"fill_miss_value\",MostFrequentImputer()),\n",
    "    (\"encoder\",OneHotEncoder(sparse=False)),\n",
    "                            ])\n",
    "\n",
    "full_data_transformer = ColumnTransformer([\n",
    "    (\"numerical\",new_num_pipiline,Numerical_attribs),\n",
    "    (\"categorical\",new_cat_pipeline,Categorical_attribs)\n",
    "                                          ])\n",
    "Data_train = pd.read_csv(Train_path)\n",
    "full_data_transformer.fit(Data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch     Fare    1    2    3  female  male    C    Q    S\n",
       "0    22.0    1.0    0.0   7.2500  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0\n",
       "1    38.0    1.0    0.0  71.2833  1.0  0.0  0.0     1.0   0.0  1.0  0.0  0.0\n",
       "2    26.0    0.0    0.0   7.9250  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0\n",
       "3    35.0    1.0    0.0  53.1000  1.0  0.0  0.0     1.0   0.0  0.0  0.0  1.0\n",
       "4    35.0    0.0    0.0   8.0500  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0\n",
       "..    ...    ...    ...      ...  ...  ...  ...     ...   ...  ...  ...  ...\n",
       "886  27.0    0.0    0.0  13.0000  0.0  1.0  0.0     0.0   1.0  0.0  0.0  1.0\n",
       "887  19.0    0.0    0.0  30.0000  1.0  0.0  0.0     1.0   0.0  0.0  0.0  1.0\n",
       "888  28.0    1.0    2.0  23.4500  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0\n",
       "889  26.0    0.0    0.0  30.0000  1.0  0.0  0.0     0.0   1.0  1.0  0.0  0.0\n",
       "890  32.0    0.0    0.0   7.7500  0.0  0.0  1.0     0.0   1.0  0.0  1.0  0.0\n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to get the different columns\n",
    "\n",
    "# Get the columns for the one hot encoder\n",
    "cat_features = []\n",
    "\n",
    "full_cat_list = full_data_transformer.named_transformers_['categorical']['encoder'].categories_\n",
    "\n",
    "for cat_list in full_cat_list:\n",
    "    for elt in cat_list:\n",
    "        cat_features.append(elt)\n",
    "        \n",
    "Data_prepared = full_data_transformer.fit_transform(Data_train)\n",
    "Features_list = Numerical_attribs + cat_features\n",
    "\n",
    "# We can rebuild a pandas DataFrame\n",
    "pd.DataFrame(Data_prepared,columns=Features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
